---
title: "4 Statistik"
format: html
---

```{r, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(palmerpenguins)
library(afex)
penguins <- palmerpenguins::penguins
penguins <- penguins %>%
  tibble::rownames_to_column(var = "id")

dat_full <- read_csv("raw/dat_full.csv")

dat_long <- dat_full |>
      pivot_longer(
        cols = c(pre1, pre4),
        names_to = "time_rating",
        values_to = "rating"
      )

```

::: callout-note
Unabh√§ngig von den konkreten Fragen l√§sst sich [hier](https://methodenlehre.github.io/statistik-IV/) das Skript zu Statistik IV von Boris Mayer und Stefan Thoma abrufen, welches insbesondere Themen zur Messwiederholung und mixed-ANOVAs abdeckt. Bei Fragen kann zus√§tzlich die Methodenberatung kontaktiert werden!
:::

## Wie l√§sst sich bestimmen, wann welcher statistische Test angemessen ist?

Der [Statistikbaum der UZH](https://www.methodenberatung.uzh.ch/de/datenanalyse_spss.html) bietet hierzu eine gute √úbersicht. Aber auch er ersetzt leider keine tiefergehende Besch√§ftigung mit den Daten und dem Messdesign. Eine vollst√§ndige Antwort l√§sst sich hierauf leider nicht geben.

## Was pr√ºft eine One-way ANOVA?

Die ANOVA pr√ºft generell die Frage, ob die beobachtete Variation in den Daten gr√∂√üer ist, als durch Zufall zu erwarten w√§re. Der zentrale Gedanke der ANOVA ist, dass Unterschiede zwischen Gruppen dann als bedeutsam gelten, wenn die Gruppenmittelwerte stark voneinander abweichen, w√§hrend die Streuung innerhalb der Gruppen gering ist, sodass es unwahrscheinlich ist, dass diese Unterschiede nur durch Zufall entstanden sind.

Dieses Verh√§ltnis wird durch den F-Wert ausgedr√ºckt:

$F = \frac{\text{Varianz zwischen den Gruppen}}{\text{Varianz innerhalb der Gruppen}}$.

**Die One-Way ANOVA beantwortet die Frage:**

> *Unterscheiden sich mehr als zwei Gruppen in einer abh√§ngigen Variable?*

**Beispiel:**

Beispielsweise wird untersucht, ob sich Pinguine in ihrer Schnabell√§nge zwischen mehreren Gruppen (z. B. Inseln) unterscheiden. Da mehr als zwei Gruppen verglichen werden, ist eine One-Way ANOVA angemessen.

Da der p-Wert \< 0.05 ist, ist die ANOVA signifikant. Das bedeutet, dass sich mindestens zwei der Gruppen signifikant voneinander unterscheiden. Welche Gruppen sich konkret unterscheiden, kann jedoch erst mit Post-hoc-t-Tests √ºberpr√ºft werden.

Das generalized `Œ∑¬≤` (ges) gibt an, wie viel Varianz der abh√§ngigen Variable durch den Faktor erkl√§rt wird. In diesem Fall erkl√§rt die Gruppenzugeh√∂rigkeit (z. B. Spezies) ca. 70 % der Varianz der Schnabell√§nge.

```{r, echo = TRUE}
model_1 <- aov_4(bill_length_mm ~ species + (1 |id), data = penguins)

summary(model_1)
```

[üåêErkl√§rvideo ANOVA](https://www.youtube.com/watch?v=ITf4vHhyGpc)

[üåêErkl√§rvideo ANOVA + t-Test](https://www.youtube.com/watch?v=4dIYRo5WsIo)

[üåêErkl√§rvideo: **Using Linear Models for t tests and ANOVA, Clearly Explained!!!**](http://youtube.com/watch?v=R7xd624pR1A&t=338s)

## Was pr√ºft ein post hoc t-Test?

Der Post-hoc t-Test ist die logische Konsequenz aus einer signifikanten ANOVA. Der t-Test pr√ºft, ob sich die Mittelwerte zweier Gruppen in der abh√§ngigen Variable unterscheiden.

**Der post-hoc t-Test beantwortet die Frage:**

> *Welche zwei Gruppen unterscheiden sich sich signifikant in der abh√§ngigen Variable?*?\*

**Beispiel:**

Beispielsweise wird untersucht, ob sich Pinguine in ihrer Schnabell√§nge zwischen mehreren Gruppen (z. B. Inseln) unterscheiden. Eine ANOVA hat gezeigt, dass es signifikante Unterschiede gibt. Nun werden Post-hoc t-Tests durchgef√ºhrt, um herauszufinden zwischen welchen Gruppen diese signifikante Unterschiede genau vorkommen.

Da es drei Spezies (Gentoo, Chinstrap, Adelie) gibt k√∂nnen drei verschiedene Gruppenvergleiche berechnet werden.

Auf Basis von Stichprobendaten wird untersucht, ob sich Pinguine der Spezies Adelie und Chinstrap in ihrer Schnabell√§nge (bill_length_mm) unterscheiden. Das signifikante Ergebnis (p \< 0.05) spricht daf√ºr, dass sich die mittlere Schnabell√§nge dieser beiden Gruppen auf Populationsebene unterscheidet.

```{r, echo = TRUE}

penguins_filtered <- penguins |>
  filter(species != "Gentoo")

t.test(bill_length_mm ~ species, data = penguins_filtered)

```

[üåêErkl√§rvideo ANOVA](https://www.youtube.com/watch?v=ITf4vHhyGpc)

[üåêErkl√§rvideo ANOVA + t-Test](https://www.youtube.com/watch?v=4dIYRo5WsIo)

[üåêErkl√§rvideo: **Using Linear Models for t tests and ANOVA, Clearly Explained!!!**](http://youtube.com/watch?v=R7xd624pR1A&t=338s)

## Was pr√ºft eine mixed-ANOVA?

Die Mixed-ANOVA pr√ºft generell die Frage, ob die beobachtete Variation in den Daten gr√∂√üer ist, als durch Zufall zu erwarten w√§re.\
Der zentrale Gedanke der Mixed-ANOVA besteht darin, dass Unterschiede dann als bedeutsam gelten, wenn sich die Mittelwerte sowohl **zwischen den Gruppen** (Between-Subjects-Faktor) als auch **√ºber Messzeitpunkte bzw. Bedingungen hinweg** (Within-Subjects-Faktor) deutlich unterscheiden, w√§hrend die Streuung innerhalb der jeweiligen Gruppen und Messwiederholungen gering ist.

Unter diesen Voraussetzungen ist es unwahrscheinlich, dass die beobachteten Effekte und Interaktionen lediglich durch Zufall entstanden sind.

Dieses Verh√§ltnis wird durch den F-Wert ausgedr√ºckt:

$F = \frac{\text{Varianz zwischen den Gruppen}}{\text{Varianz innerhalb der Gruppen}}$.

**Die mixed-ANOVA beantwortet die Frage:**

> *Sind die Verl√§ufe der abh√§ngigen Variable √ºber Messzeitpunkte bzw. Bedingungen hinweg zwischen den Gruppen unterschiedlich?*

**Beispiel:**

Die 2√ó3 ANOVA im Grinschgl et al. (2021) Paper beantwortet die folgenden Fragen:\
Gibt es Unterschiede zwischen den Feedbackgruppen, gibt es Ver√§nderungen √ºber die Zeit (`Pre1` vs. `Pre4`), und unterscheiden sich diese zeitlichen Ver√§nderungen zwischen den Gruppen (`above` vs. `control` vs. `below`)?

```{r, echo = TRUE}
mixed_anova <- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)

summary(mixed_anova)
```

Der signifikante Haupteffekt der Feedbackgruppe (`group_all`) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabh√§ngig vom Zeitpunkt der Messung.

Der signifikante Interaktionseffekt zeigt, dass sich die Ver√§nderung der Ratings √ºber die Zeit zwischen den Feedbackgruppen unterscheidet. üëâDer Effekt der Zeit ist **nicht f√ºr alle Gruppen gleich.**

## Was ist das partielle Œ∑¬≤ und wie unterscheidet es sich von dem generalisierten Œ∑¬≤?

Das generalisierte und partielle Œ∑¬≤ sind beides Masse, welche den Anteil an erkl√§rter Varianz einer abh√§ngigen Variable angeben. Das generalisierte Œ∑¬≤ berechnet den Anteil der erkl√§rten Varianz einer abh√§ngigen Variable unter Einbezug der gesamten Varianz, also aller Effekte. Das partielle Œ∑¬≤ beachtet bei der Berechnung des Anteils an erkl√§rter Varianz f√ºr die abh√§ngige Variable nicht die gesamte Varianz, sondern nur jene, welche dem zuvor definierten Effekt zugeschrieben werden kann.

::: callout-note
Weiterf√ºhrende Informationen finden sich [hier](https://matheguru.com/stochastik/effektstarke.html).
:::

## Wozu muss Sph√§rizit√§t gegeben sein und wie kann man diese testen?

Unter Sph√§rizit√§t versteht man die Annahme, dass bei Messwiederholungen die Differenzen von zwei beliebigen Messwiederholungen √§hnliche Varianzen aufweisen. Dies kann mit dem Mauchly-Test gepr√ºft werden. Laut Nullhypothese sind die entsprechenden Varianzen gleich, laut Alternativhypothese sind die entsprechenden Varianzen unterschiedlich. Dementsprechend spricht ein signifikanter Mauchly-Test f√ºr eine Verletzung der Sph√§rizit√§tsannahme. In diesem Fall kann auf die Greenhouse-Geisser Korrektur zur√ºckgegriffen werden.

## Was macht eine Tukey-Korrektur und was sagt uns das Ergebnis?

Die Tukey-Korrektur wird angewendet, um im Anschluss an eine signifikante ANOVA die Mittelwertsunterschiede der einzelnen Gruppen unter Kontrolle f√ºr multiples Testen einzeln zu untersuchen. Hierdurch wird eine Inflation der falsch-positiven Rate (Œ±-Fehler) bzw. des p-Wertes vermieden. Bei Verwendung dieses Tests k√∂nnen die Ergebnisse der Mittelwertsvergleiche somit unmittelbar auf ihre Signifikanz hin bewertet werden.

## Wann ben√∂tigt die Berechnung einer ANOVA einen wide-Datensatz und wann ben√∂tigt die Berechnung einer ANOVA einen long-Datensatz?

In welchem Format der Datensatz vor der Berechnung einer ANOVA vorliegen muss h√§ngt von der verwendeten ANOVA-Funktion ab und kann nicht pauschal beantwortet werden. Grunds√§tzlich gilt aber, f√ºr eine ANOVA ohne Messwiederholung ist ein wide-Datensatz meist ausreichend. Die Funktion `aov_4()`, welche bei ANOVAs mit Messwiederholung verwendet werden kann, ben√∂tigt eine gesonderte Variable, welche den Zeitpunkt der Messung angibt, sprich das long-Format. Hier ein Beispiel wie die Umwandlung in ein long-Format und eine anschliessende Berechnung von einer ANOVA mit Messwiederholung aussehen k√∂nnte:

```{r}
#| echo: true
#| eval: false

data_long <- data_wide |> 
  pivot_longer(
    cols = c(Spalte1, Spalte2, Spalte3), 
    names_to = "Hier kommt der Name der Spalte rein, in welcher die fr√ºheren Spalten√ºberschriften abgelegt sind", 
    values_to = "Hier kommt der Name der Spalte rein, in welcher die Werte der entsprechenden fr√ºheren Spalten abgelegt sind"
  )

afex::aov_4(value ~ treatment + (time | Personenidentifikationscode), data = data_long) # Beispiel mit(!) Messwiederholung
```

::: callout-note
F√ºr die Funktion `aov_4()` gibt es aus [Statistik-IV von Boris Mayer und Stefan Thoma](https://methodenlehre.github.io/statistik-IV/) noch tiefere und beispielhafte Ausf√ºhrungen.
:::

## Was wird bei einem Levene-Test berechnet bzw. gepr√ºft?

Der Levene-Test pr√ºft die Varianzhomogenit√§t der abh√§ngigen Variablen zwischen Gruppen. Als Nullhypothese gilt hierbei, dass die Varianzen der abh√§ngigen Variablen zwischen den Gruppen gleich sind. Als Alternativhypothese gilt, dass die Varianzen zwischen den Gruppen unterschiedlich sind. Dementsprechend besagt ein **signifikanter Levene-Test**, dass es Varianzunterschiede zwischen den Gruppen gibt und die **Annahme der Varianzhomogenit√§t verworfen** werden muss.

## Wird ein Levene-Test f√ºr den between-Faktor berechnet und muss diese Berechnung f√ºr jede abh√§ngige Variable einzeln gemacht werden?

F√ºr beide Fragen gilt: Ja! Der Levene-Test vergleicht die Varianzen von mindestens zwei Gruppen. Dementsprechend kann ein Levene-Test nur f√ºr einen between-Faktor durchgef√ºhrt werden. Dar√ºber hinaus kann ein einzelner Levene-Test nur die Varianzverteilung einer abh√§ngigen Variable (√ºber alle Gruppen hinweg) betrachten. Daher muss f√ºr jede abh√§ngige Variable, f√ºr die die Annahme der Varianzhomogenit√§t ben√∂tigt wird und infrage steht, ein Levene-Test berechnet werden.

## Ist vor der Berechnung einer ANOVA notwendigerweise ein Levene-Test durchzuf√ºhren?

Die Durchf√ºhrung eines Levene-Tests vor der ANOVA ist dann notwendig, wenn die Varianzhomogenit√§t zwischen Gruppen nicht anderweitig ersichtlich ist. Zeigen die Daten beispielsweise gleich grosse Stichproben und normalverteilte Verteilungen der Werte innerhalb der Gruppen, dann kann von Varianzhomogenit√§t auch ohne den Levene-Test ausgegangen werden. **Vor der Datenanalyse** sollte festgelegt werden, ob ein Levene-Test berechnet wird oder nicht, und gegebenenfalls ein Verfahren definiert werden f√ºr den Fall, dass die Varianzhomogenit√§t nicht gegeben ist (z.B. ein nichtparametrisches Verfahren wie die Welch-ANOVA).

## Welche Masse f√ºr Effektst√§rken werden √ºblicherweise bei einer ANOVA und einem (post-hoc) t-Test berichtet?

Bei einer ANOVA wird im Rahmen des Seminars, sofern nicht anders verlangt, das Effektst√§rkemass Œ∑¬≤ oder partielles Œ∑¬≤ berichtet. Bei (post-hoc) t-Tests wird im Rahmen des Seminars, sofern nicht anders verlangt, das Effektst√§rkemass von Cohens\` d verwendet.

## Bei der Analyse der internen Konsistenz mit der Funktion `alpha()` erscheint die Fehlermeldung: ‚ÄûWarnung: Some items were negatively correlated with the first principal component and probably should be reversed. To do this, run the function again with the 'check.keys=TRUE' option‚Äú. Was bedeutet diese Warnmeldung und kann sie einfach ignoriert oder muss sie weiter ber√ºcksichtigt werden?

Diese Warnmeldung - in Verbindung mit der Funktion `alpha()` zur Berechnung der internen Konsistenz - weist darauf hin, dass ein Item invers codiert sein k√∂nnte, da es nur einen geringen oder sogar negativen Zusammenhang zu den anderen Items aufweist. Dies kann daran liegen, dass das Item den Versuchspersonen invers vorgelegt worden war und lediglich vergessen wurde, die Skala anschliessend erneut zu invertieren. Das Item kann aber auch in die ‚Äûrichtige‚Äú Richtung codiert sein und die Kennwerte des Items erkl√§ren sich durch weitere Umst√§nde wie beispielsweise eine kleine Stichprobe. Abh√§ngig davon welcher Fall zutrifft m√ºsste das Item vor der Berechnung der internen Konsistenz entweder noch invertiert oder die Warnmeldung kann ignoriert werden.

## Wie wird Cohens d f√ºr eine ANOVA berechnet?

Kurze Antwort: Gar nicht. Das Effektst√§rkemass einer ANOVA ist das partielle oder generelle Œ∑¬≤. Cohens d ist das Effektst√§rkemass f√ºr einen (post-hoc) t-Test und folgt dieser Formel: $d = \frac{M_1 - M_2}{SD_{pooled}}$.

**Beispiel**:

```{r}
dat_full_below_above <- dat_full |> 
  filter(group_all != "control")

dat_full_below_above$group_all <- as.factor(dat_full_below_above$group_all)

t.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)
effsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)
```
