---
title: "Hands On ‚Äì Analyze (Einheiten 11 und 12)"
editor: visual
bibliography: references.bib
draft: true
---

```{r, echo = FALSE, results = 'hide', message= FALSE, warning=FALSE}
library(tidyverse)

dat_full <- read_csv("data/raw/dat_full.csv")
dat_long <- read_csv(here::here("scripts/02_excercises/data/processed/data_long.csv"))
```

Bei Bedarf finden sich hier nochmal die Slides zur EH11:

::: {=html}
<iframe src="../01_slides/EH_11.html" width="100%" height="500" style="border:0; display:block; margin: 0 0 2rem 0;">

</iframe>
:::

Und hier die Slides zur EH12:

::: {=html}
<iframe src="../01_slides/EH_12.html" width="100%" height="500" style="border:0; display:block; margin: 0 0 2rem 0;">

</iframe>
:::

# Lernziele

‚úÖ ggplot2

‚úÖ Korrelationen

‚úÖ Regressionen

‚úÖ t-Tests

::: callout-important
F√ºr die heutigen √úbungen ben√∂tigen wir den **Wide Datensatz** `dat_full` sowie den **Long Datensatz** `dat_long`
:::

------------------------------------------------------------------------

## Visualize - √úbungen zu `ggplot2`

[üìö Einf√ºhrung in R - Kapitel 5](https://methodenlehre.github.io/einfuehrung-in-R/chapters/05-plotting.html)

[üìö R for Data Science - Kapitel 1](https://r4ds.hadley.nz/data-visualize.html)

[üìöR for Data Science - Kapitel 11](https://r4ds.hadley.nz/communication.html)

::: {.callout-note collapse="true"}
### Tabelle mit h√§ufig verwendeten Geoms()

| Geom | Funktion | Einsatzbereich | Bild / Beispiel |
|----|----|----|----|
| **geom_point()** | Streudiagramm | Zwei numerische Variablen vergleichen (x = Var1, y = Var2) | ![](../../images/EH_10/geom_point.png) |
| **geom_jitter()** | Jitter-Plot | Punkte leicht versetzen, um √úberlappung zu vermeiden (v. a. bei kategorialem x) | ![](../../images/EH_10/geom_jitter.png) |
| **geom_line()** | Liniendiagramm | Werteverlauf √úber kontinuierliche x-Achse darstellen | ![](../../images/EH_10/geom_line.png) |
| **geom_bar()** | Balkendiagramm | H√§ufigkeiten oder Aggregationen f√ºr Kategorien (x = Gruppe) | ![](../../images/EH_10/geom_bar.png) |
| **geom_histogram()** | Histogramm | Verteilung einer numerischen Variable (x = Wert) | ![](../../images/EH_10/geom_histogram.png) |
| **geom_boxplot()** | Boxplot | Verteilungen √ºber Gruppen vergleichen (x = Gruppe, y = Wert) | ![](../../images/EH_10/geom_boxplot.png) |
:::

::: {.callout-note collapse="true"}
## Cheatsheet ggplot2

<iframe src="../../PDFs/ggplot.pdf" width="100%" height="500px">

</iframe>
:::

**Im folgenden wollen wir Figure 4 aus @grinschgl2021 reproduzieren:**

```{r, echo = FALSE}

dat_full <- dat_full |> 
  mutate(mmq_mean = rowMeans(select(dat_full, starts_with("question")), # bedingt, dass neben den 18 Variablen vom mmq sonst keinerlei andere Variablen mit "question" starten
                             na.rm = TRUE))

group_summary <- dat_full %>%
  group_by(group_all) %>%
  summarize(
    group_mean_mmq = mean(mmq_mean),
    se_mmq = sd(mmq_mean) / sqrt(n())
  )


group_summary$group_all <- factor(group_summary$group_all,
                                  levels = c("below", "control", "above"))

ggplot(group_summary, aes(x = group_all, y = group_mean_mmq)) +
  geom_col(fill = "gray", color = "black") + 
  geom_errorbar(
    aes(ymin = group_mean_mmq - se_mmq, ymax = group_mean_mmq + se_mmq),  
    width = 0.2,
    color = "black"
  ) +
  labs(
    x = "Feedback Group",
    y = "Mean MMQ Ratings",
    title = "Group Means of Mean MMQ with SE Error Bars"
  ) +
  ylim(0, 4)+
  theme_classic()
```

### **Vorbereitungen:**

Um die Mittelwerte plotten zu k√∂nnen, m√ºssen wir die Gruppenmittelwerte und Standardfehler berechnen. Passe daf√ºr den Codeblock an:

Im Hands-on Block 4 haben wir bereits mit *dplyr* die MMQ-Skalenwerte ‚Äûmmq_mean‚Äú pro Person berechnet. Nutze nun die *dplyr*-Funktionen, insbesondere `group_by()`, um den durchschnittlichen MMQ-Wert pro Gruppe (`group_all`) sowie den Standardfehler zu berechnen. Die Formel f√ºr den Standardfehler lautet: **SE = SD / ‚àön** und kann z.b so berechnet werden. `se_mmq = sd(mmq_mean) / sqrt(n())` . Erg√§nze den Code unten mit den n√∂tigen Angaben. Lege group_all in deinem summary als Faktor fest mit den Levels in der Reihenfolge: "below", "control", "above".

::: {.callout-note collapse="true"}
Der **Standardfehler des Mittelwerts (SEM)** beschreibt **wie stark der gesch√§tzte Stichprobenmittelwert zuf√§llig vom wahren Populationsmittelwert abweichen kann**. Er ist damit ein **Mass f√ºr die Pr√§zision** des Mittelwerts.
:::

```{r, echo=TRUE, eval = FALSE}

dat_full <- dat_full |> 
  mutate(mmq_mean = rowMeans(select(dat_full, starts_with("question")))


group_summary <- dat_full %>%
  group_by(XXXXXXX) %>%
  summarize(
    group_mean_mmq = mean(XXXXXX),
    se_mmq = sd(XXXXXX) / sqrt(n())
  )

group_summary$group_all <- factor(group_summary$group_all,
                                  levels = c("XXXXX", "XXXXX", "XXXXX"))


```

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, echo = TRUE}

dat_full <- dat_full |> 
  mutate(mmq_mean = rowMeans(select(dat_full, starts_with("question"))))


group_summary <- dat_full %>%
  group_by(group_all) %>%
  summarize(
    group_mean_mmq = mean(mmq_mean),
    se_mmq = sd(mmq_mean) / sqrt(n())
  )

group_summary$group_all <- factor(group_summary$group_all,
                                  levels = c("below", "control", "above"))

```
:::

### **1. Erstelle einen leeren Plot und gib deinen Datensatz an**

Beginne mit:

-   `ggplot()` und deinem Datensatz

::: {.callout-note collapse="true" title="L√∂sung"}
```{r}

plot_base <- group_summary |> 
  ggplot()

```
:::

### **2. Definiere die Aesthetic Mappings**

Lege fest:

-   welche Variable auf der **x-Achse** liegt

-   welche Variable auf der **y-Achse** liegt

::: {.callout-note collapse="true" title="L√∂sung"}
```{r}

plot_base_updated <- plot_base +
  aes(x = group_all, y = group_mean_mmq)

```
:::

### **3. F√ºge `geom_col()` dem Plot hinzu**

Damit zeichnest du die Balken f√ºr die Gruppenmittelwerte.

-   `color =` f√ºr Konturen

-   `fill =` f√ºr die F√ºllfarben der Balken

::: {.callout-note collapse="true" title="L√∂sung"}
```{r}

plot_base_updated <- plot_base_updated +
  geom_col(fill = "gray", color = "black")

```
:::

### **4. F√ºge Fehlerbalken hinzu**

Nutze `geom_errorbar()` und definiere innerhalb von `aes()`:

-   `ymin = mean - se` - F√ºge die passenden Variablen ein.

-   `ymax = mean + se` - F√ºge die passenden Variablen ein.

Passe die Breite der Fehlerbalken mit `width =` an.

::: {.callout-note collapse="true" title="L√∂sung"}
```{r}

plot_base_updated <- plot_base_updated +
  geom_errorbar(
    aes(ymin = group_mean_mmq - se_mmq, ymax = group_mean_mmq + se_mmq),  
    width = 0.2,
    color = "black"
  )

```
:::

### **5. F√ºge Titel und Achsenbeschriftungen hinzu**

Nutze daf√ºr `labs()`. Ver√§ndere das theme zu `theme_classic()`

::: {.callout-note collapse="true" title="L√∂sung"}
```{r}

plot_base_updated <- plot_base_updated +
  labs(
    x = "Feedback Group",
    y = "Mean MMQ Ratings",
    title = "Group Means of Mean MMQ with SE Error Bars"
  ) +
  theme_classic()

```
:::

### **6. Stelle sicher, dass der vollst√§ndige Wertebereich sichtbar ist**

-   mit `ylim(0, 4)`

::: {.callout-note collapse="true" title="L√∂sung"}
```{r}

plot_final <- plot_base_updated +
  ylim(0, 4)
plot_final
```
:::

------------------------------------------------------------------------

Nun wollen wir den zweiten Plot aus @grinschgl2021 reproduzieren.

Erg√§nze daf√ºr den folgenden Code an den n√∂tigen Stellen mit den passenden Werten und Argumenten.

-   Lade zuerst den in der letzten Woche gespeicherten *Long-Datensatz*.

-   Ersetze anschliessend die Platzhalter **"XXXXXX"** durch die erforderlichen Werte, um den Plot zu reproduzieren.

```{r echo = TRUE, eval = FALSE}

descriptives <- dat_long |> 
  group_by(XXXXXX, XXXXXXX) |> 
  summarize(N = length(rating),
               mean_d = mean(rating),
               sd_d   = sd(rating),
               se_d   = sd_d / sqrt(N)
)

descriptives$group_all <- factor(descriptives$group_all, c("above", "control", "below"))

rate_plot <- descriptives |> 
  ggplot(aes(x = XXXXXX, 
             y = XXXXXX, 
             group = XXXX)) 

rate_plot +
  geom_line(aes(color = group_all, linetype = group_all), size = 1.2) +
  geom_errorbar(aes(ymin = mean_d - se_d, ymax = mean_d + se_d), width = .1) +
  scale_color_manual(values = c("green4", "red", "black")) +
  theme_classic() +
  labs(title = "XXXXXXX") +
  ylab("XXXXXXXX") +
  xlab("XXXXXXXXX") +
  theme(plot.title = element_text(hjust = 0.5, size = 12, face = "bold"), 
        axis.text = element_text(size = 11), axis.title = element_text(size = 14))

```

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, echo = TRUE, message=TRUE, warning= FALSE}
descriptives <- dat_long |> 
  group_by(group_all, time_rating) |> 
  summarize(N = length(rating),
               mean_d = mean(rating)*10,
               sd_d   = sd(rating)*10,
               se_d   = sd_d / sqrt(N)
)

descriptives$group_all <- factor(descriptives$group_all, c("above", "control", "below"))

rate_plot <- descriptives |> 
  ggplot(aes(x = time_rating, 
             y = mean_d, 
             group = group_all)) 

rate_plot_updated <- rate_plot +
  geom_line(aes(color = group_all, linetype = group_all), size = 1.2) +
  geom_errorbar(aes(ymin = mean_d - se_d, ymax = mean_d + se_d), width = .1) +
  scale_color_manual(values = c("green4", "red", "black")) +
  theme_classic() +
  labs(title = "Subjective Performance Ratings ") +
  ylab("Percentile Rank") +
  xlab("Time") +
  theme(plot.title = element_text(hjust = 0.5, size = 12, face = "bold"), 
        axis.text = element_text(size = 11), axis.title = element_text(size = 14))
rate_plot_updated
```
:::

-   Speichere deinen Plot als PNG Datei ab.

::: {.callout-note collapse="true" title="L√∂sung"}
```{r}
ggsave(
  "rate_plot.png",
  plot = rate_plot_updated,
  width = 10,
  height = 6,
  dpi = 300
)
```
:::

------------------------------------------------------------------------

# Inferenzstatistik

::: {.callout-note collapse="true"}
## Cheatsheets Statistik

<iframe src="../../PDFs/stat_1.pdf" width="100%" height="500px">

</iframe>

<iframe src="../../PDFs/stat_3.pdf" width="100%" height="500px">

</iframe>
:::

## Korrelationen:

-   W√§hle zwei metrische Variablen aus dem Wide Datensatz aus. Berechne die Korrelation mit `cor.test()` f√ºr diese beiden Variablen.

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval = TRUE}

cor.test(dat_full$mean_d1_all, dat_full$mean_d_all)

```
:::

<!-- -->

-   Finde den Korrelationskoeffizienten *r*, den *p*-Wert und die Freiheitsgrade (df). Versuche das Ergebnis zu interpretieren.

::: {.callout-note collapse="true" title="L√∂sung"}
In dem von uns gew√§hlten Beispiel wurde die Korrelation von `mean_d1_all` mit `mean_d_all` berechnet. Der Korrelationskoeffizient r betr√§gt r = 0.78, was auf eine starke positive Korrelation hinweist. Der p-Wert ist p \< 0.001, was darauf hindeutet, dass die Korrelation statistisch signifikant ist. Die Freiheitsgrade (df) betragen 157, was auf die Anzahl der Beobachtungen minus 2 zur√ºckzuf√ºhren ist (n-2). Das die Dauer bis zur ersten Fenster√∂ffnung und die Dauer des gesamten Trials zusammenh√§ngen war inhaltlich zu erwarten.
:::

<!-- -->

-   Rufe die Hilfefunktion von `cor.test()` auf. Welche Anpassungen kannst du vornehmen, um die Korrelation einseitig (z.B. nur positiver Zusammenhang) und mit der Spearman-Methode zu berechnen?

::: {.callout-note collapse="true" title="L√∂sung"}
```{r}
?cor.test

# F√ºr eine einseitige Korrelation kannst du das Argument `alternative` verwenden, z.B. `alternative = "greater"` f√ºr eine positive Korrelation.
cor.test(dat_full$mean_d1_all, dat_full$mean_d_all, alternative = "greater")

# F√ºr die Spearman-Methode kannst du das Argument `method` verwenden, z.B. `method = "spearman"`.
cor.test(dat_full$mean_d1_all, dat_full$mean_d_all, method = "spearman")
```
:::

::: {.callout-note collapse="true"}
### Korrelationen

Linearer Zusammenhang (Kovarianz) zweier Variablen. Positive Korrelation = hohe Auspr√§gungen einer Variable h√§ngen mit hohen Auspr√§gungen einer anderen Variable zusammen. Negative Korrelation = Hohe Auspr√§gungen einer Variable h√§ngen mit niedrigen Auspr√§gungen einer anderen Variable zusammen. Korrelationskoeffizient *r* kann von -1 bis +1 gehen. Der Korrelationstest testet ob r sich signifikant von 0 (kein Zusammenhang unterscheidet). F√ºr Pearson Korrelationen sollte die Normalverteilung der Residuen gegeben sein. Alternative: Spearman Korrelation.
:::

------------------------------------------------------------------------

## Regressionen

::: {.callout-note collapse="true"}
### **Tabelle: Funktionen f√ºr Regressionen und verwandte Analysen in R**

| Funktion | Beschreibung |
|----|----|
| **lm(y \~ x)** | Einfache lineare Regression mit einer abh√§ngigen Variablen *y* und einem Pr√§diktor *x*. |
| **lm(y \~ x1 + x2)** | Multiple Regression mit einer abh√§ngigen Variablen *y* und zwei Pr√§diktoren *x1* und *x2*. |
| **summary()** | Gibt die Ergebnisse der Regressionsanalyse f√ºr ein Regressionsmodell aus. |
| **confint()** | Konfidenzintervalle f√ºr die Regressionskoeffizienten. |
| **fitted()** | Vorhergesagte Werte des Regressionsmodells. |
| **resid()** | Residuen des Regressionsmodells. |
| **predict()** | Vorhergesagte Werte f√ºr bestimmte Werte der Pr√§diktorvariablen. |
| **anova()** | Vergleicht die Determinationskoeffizienten zweier Regressionsmodelle mit einem F-Test. |
| **vif()** \* | Variance Inflation Factors (VIF) f√ºr jeden Pr√§diktor; aus dem *car*-Paket. |

\* aus zus√§tzlichen Paketen
:::

-   Paket `‚Äûcar‚Äú` installieren und laden.

```{r, echo = FALSE}

library(car)

```

-   Mach aus deiner davor berechneten Korrelation nun ein Regressionsmodel mit der Funktion `model <- lm(outcome ~ predictor, data)`. Schau dir den Output mit `summary(model)` an und versuche ihn zu interpretieren.

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval = TRUE}

model_1 <- lm(mean_d1_all ~ mean_d_all, data = dat_full)

summary(model_1)

```

Mit `summary(model_1)` erhalten wir Informationen √ºber das Regressionsmodell. Der Koeffizient f√ºr `mean_d_all` zeigt an, wie stark sich `mean_d1_all` √§ndert, wenn `mean_d_all` um eine Einheit steigt. Der p-Wert f√ºr diesen Koeffizienten ist signifikant (p \< 0.001), was darauf hinweist, dass `mean_d_all` Pr√§diktor signifikant zur Vorhersage der abh√§ngigen Variable `mean_d1_all` beitr√§gt. Das R-Quadrat (R¬≤) betr√§gt 0.64, was bedeutet, dass etwa 64% der Varianz in `mean_d1_all` durch `mean_d_all` erkl√§rt wird.

Wie die folgende logische Abfrage zeigt, entspricht die Wurzel von R-Squared der Korrelation zwischen den beiden Variablen.

```{r}

cor(dat_full$mean_d1_all, dat_full$mean_d_all) == sqrt(summary(model_1)$r.squared)

```
:::

-   Erg√§nze das Modell nun um eine weitere Pr√§diktorvariable (mit + Variable), sodass du eine multiple Regression berechnest. Hier m√ºssen wir auf Multikollinearit√§t testen ‚Äì mit `vif(model)` aus dem ‚Äûcar‚Äú Paket (die Werte sollten gr√∂√üer als 0.10 sein, sodass keine Multikollinearit√§t vorliegt). Berechne auch die Konfidenzintervalle der Beta-Koeffizienten mit `confint(model)`.

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval = TRUE}

model_2 <- lm(mean_d1_all ~ mean_d_all + mean_rl_all, data = dat_full)

summary(model_2)

vif(model_2)

confint(model_2)

```

Mit summary(model_2) erhalten wir auch Informationen √ºber das neue, multiple Regressionsmodell. Die Koeffizienten f√ºr `mean_d_all` und `mean_rl_all` zeigen an, wie stark sich `mean_d1_all` √§ndert, wenn diese Pr√§diktoren um eine Einheit steigen. Beide Pr√§diktoren haben signifikante p-Werte (p \< 0.001), was darauf hinweist, dass sie signifikant zur Vorhersage der abh√§ngigen Variable beitragen. Das R-Quadrat (R¬≤) betr√§gt 0.77, was bedeutet, dass etwa 77% der Varianz in `mean_d1_all` durch beide Pr√∂diktoren zusammen erkl√§rt wird.

Die VIF-Werte f√ºr beide Pr√§diktoren sind unter 10, was darauf hinweist, dass keine Multikollinearit√§t vorliegt.

Die Konfidenzintervalle f√ºr die Koeffizienten geben den Bereich an, in dem wir mit 95%iger Sicherheit erwarten k√∂nnen, dass die wahren Koeffizientenwerte liegen. Beinhalten diese Konfidenzintervalle die 0 **nicht**, dann gelten die Koeffizienten ebenfalls als signifkant (unterschiedlich zu null).
:::

:::: {.callout-note collapse="true"}
**Fortgeschritten/Freiwillig:**

Berechne eine einfache logistische Regression zwischen Strategien (ohne strategies == 3) und Offloading (mean_rl_all) mit dem Wide Datensatz. Nimm das Statistik III Cheatsheet von Dr. Boris Mayer zur Hand. Tipp: Du musst die Strategien in 0 und 1 umkodieren.

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval = TRUE}

dat_log <- dat_full |> 
  filter(strategies != 3) |>  # entferne Strategie 3
  mutate(strategy_bin = if_else(strategies == 1, 0, 1)) # setze alle Strategien 1 auf 0 und 2 auf 1

model <- glm(strategy_bin ~ mean_rl_all, # hier soll das Offloading die Vorhersage der Strategiewahl √ºbernehmen
             data = dat_log,
             family = binomial)

summary(model)

```

Einmal mehr erhalten wir mit `summary()` informationen √ºber das von uns gerechnete Modell. Der Koeffizient f√ºr `mean_rl_all` zeigt an, wie sich die Wahrscheinlichkeiten (Log-Odds) der Wahl von Strategie 2 (im Vergleich zu Strategie 1) √§ndern, wenn `mean_rl_all` um eine Einheit steigt. Der p-Wert f√ºr diesen Koeffizienten ist signifikant (p \< 0.05), was darauf hinweist, dass `mean_rl_all` signifikant zur Vorhersage der Strategiewahl beitr√§gt.
:::
::::

------------------------------------------------------------------------

## *t*-Tests f√ºr abh√§ngige Stichproben

::: {.callout-note collapse="true"}
### **Tabelle: Funktionen f√ºr *t*-Tests und verwandte Analysen in R**

| Funktion | Beschreibung |
|----|----|
| **t.test** | Allgemeine Funktion f√ºr verschiedene t-Tests: Ein-Stichproben-t-Test, t-Test f√ºr unabh√§ngige Stichproben und t-Test f√ºr abh√§ngige Stichproben. |
| **t.test(av, mu = x)** | Ein-Stichproben-t-Test. **av** = abh√§ngige Variable. **x** = Vergleichswert der Population. |
| **t.test(av \~ uv)** | Welch-t-Test f√ºr **unabh√§ngige Stichproben**. **av** = abh√§ngige Variable, **uv** = Gruppenvariable. |
| **t.test(av \~ uv, var.equal = TRUE)** | Klassischer t-Test f√ºr unabh√§ngige Stichproben (Varianzen vorausgesetzt gleich). |
| **t.test(av1, av2, paired = TRUE)** | t-Test f√ºr **abh√§ngige Stichproben** (z. B. Pr√§‚ÄìPost). **av1** und **av2** = gemessene Variablen. |
| **leveneTest(av, uv)** \* | Levene-Test auf Varianzhomogenit√§t f√ºr unabh√§ngige Gruppen. Aus dem **car**-Paket. |
| **effsize::cohen.d()** \* | Berechnet die standardisierte Effektgr√∂√üe **Cohen‚Äôs d** + Konfidenzintervall. Aus dem **effsize**-Paket. |

\* Funktionen aus zus√§tzlichen Paketen.
:::

-   Paket `‚Äûeffsize‚Äú` installieren und laden.

```{r, echo = FALSE}

library(effsize)

```

-   Wir wollen einen t-Test f√ºr unabh√§ngige Stichproben durchf√ºhren, um das Pre 4 Rating der `‚Äûabove‚Äú` und `‚Äûbelow‚Äú` Gruppen zu vergleichen. Starte mit einem `leveneTest()` aus dem `‚Äûcar‚Äú` Paket um die Varianzhomogenit√§t zu pr√ºfen. Tipp: Filtere die Daten, sodass nur die beiden Gruppen `‚Äûabove‚Äú` und `‚Äûbelow‚Äú` beinhaltet sind (d.h. ohne die Gruppe `‚Äûcontrol‚Äú`).

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval = TRUE}

dat_full_below_above <- dat_full |> 
  filter(group_all != "control")

dat_full_below_above$group_all <- as.factor(dat_full_below_above$group_all)

leveneTest(dat_full_below_above$pre4, dat_full_below_above$group_all)

```

Der Levene Test pr√ºft die Homogenit√§t der Varianzen zwischen den Gruppen. Ein nicht-signifikanter p-Wert (p \> 0.05) deutet darauf hin, dass die Varianzen in den beiden Gruppen als gleich angenommen werden k√∂nnen. Der vorliegende Test ist nicht signifikant (p = 0.09 \> 0.05), was darauf hinweist, dass die Varianzen in den Gruppen `‚Äûabove‚Äú` und `‚Äûbelow‚Äú` als homogen betrachtet werden k√∂nnen.
:::

-   Berechne nun den entsprechenden t-Test mit `t.test()`. Du kannst auch die Hilfefunktion zu Rate ziehen. Versuche dann den Output zu verstehen bzw. das Ergebnis zu interpretieren. Tipp: Wenn die Varianzhomogenit√§t gegeben ist (d.h. der Levene Test nicht signifikant ist), muss man `var.equal = TRUE` angeben, ansonsten wird ein `Welch t-Test` berechnet.

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval = TRUE}

t.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)

```

Der students t-Test vergleicht die Mittelwerte der `pre4` Ratings zwischen den Gruppen `‚Äûabove‚Äú` und `‚Äûbelow‚Äú`. Der p-Wert weisst auf einen statistisch signifikanten Unterschied der beiden Mittelwerte hin (p \< 0.05). Das 95%-Konfidenzintervall f√ºr den Mittelwertunterschied liegt zwischen 2.03 und 3.36. Das dieser Bereich **nicht** die 0 beinhaltet spricht ebenfalls f√ºr die Signifikanz der Mittelwertsunterschiede. Unter Einbezug der beiden Gruppenmittelwerte (`mean in group above` = 5.97 und `mean in group below` 3.27) deutet das Ergebnis darauf hin, dass die `‚Äûabove‚Äú` Gruppe signifikant h√∂here `pre4` Ratings aufweist als die `‚Äûbelow‚Äú` Gruppe.
:::

-   Nun berechnen wir noch `Cohen‚Äòs d` als Effektst√§rken-Ma√ü f√ºr den Mittelwertsunterschied. Verwende daf√ºr `effsize::cohen.d()`. ÔÉ† Da es `‚Äûcohen.D‚Äú` auch im Paket `‚Äûpsych‚Äú` gibt, ist es wichtig hier `‚Äûeffsize::‚Äú` voranzusetzen.

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval = TRUE}

effsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)

```

Cohen's d betr√§gt 1.55, was auf einen gro√üen Effekt hinweist.
:::

üëâ Und schon haben wir einen der Post-Hoc t-Tests f√ºr die 2x3 ANOVA aus Grinschgl et al. (2020) berechnet (notwendig f√ºr die Abschlussarbeit)

------------------------------------------------------------------------

## *t*-Tests f√ºr abh√§ngige Stichproben

-   Berechne einen *t*-Test f√ºr abh√§ngige Stichproben um in der `‚Äûcontrol‚Äú` Gruppe `Pre 1` und `Pre 4` zu vergleichen. (D.h. filtere zun√§chst den Datensatz, sodass nur mehr die `‚Äûcontrol‚Äú` Gruppe

```{r, eval = FALSE, echo = TRUE}

t.test(datensatz$Variable1, datensatz$Variable2, paired = TRUE) 

```

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval = TRUE}

dat_full_control <- dat_full |>
  filter(group_all == "control")

t.test(dat_full$pre1, dat_full$pre4, paired = TRUE)

```

Der t-Test f√ºr abh√§ngige Stichproben (paired = TRUE) vergleicht die Mittelwerte von `pre1` und `pre4` innerhalb der `‚Äûcontrol‚Äú` Gruppe. Der p-Wert weisst auf einen signifikanten Unterschied zwischen den Mittelwerten dieser beiden Messzeitpunkte hin (p \< 0.05). Das 95%-Konfidenzintervall f√ºr den Mittelwertunterschied liegt zwischen 0.39 und 1.06, umschliesst damit nicht die 0, und zeigt dadurch ebenfalls einen signifikanten Mittelwertsunterschied zwsichen den beiden Messzeitpunkten an. Die Angabe `mean_difference` zeigt an, wie stark der Mittelwert von `pre1` auf `pre4`angestiegen ist (mean difference = 0.73).
:::

-   Wandle den t-Test nun in einen einseitigen Test mit alternative = ‚Äûgreater‚Äú oder alternative = ‚Äûless‚Äú um und berechne Cohen‚Äòs d als Effektst√§rkenma√ü (Achtung: paired = True setzen).

::: {.callout-note collapse="true" title="L√∂sung"}
```{r, eval=TRUE}

t.test(dat_full$pre1, dat_full$pre4, paired = TRUE, alternative = "greater")


library(effectsize)

cohens_d(
  dat_full$pre1,
  dat_full$pre4,
  paired = TRUE
)

```

W√§hrend der ungerichtete t-test pr√ºft, ob die Mittelwerte von `pre1` und `pre4` ungleich sind, pr√ºft der gerichtete t-test (alternative = "greater") spezifischer, ob der Mittelwert von `pre4` signifikant gr√∂√üer ist als der Mittelwert von `pre1`. Dies ist auch am Ergebnis "alternative hypothesis: true mean difference is greather than 0" erkennen. Der Unterschied im `mean_difference` ist allerdings gleich geblieben, ebenso das Resultat der Signifikanzpr√ºfung.
:::

# Am Ende deiner √úbungen - vergiss nicht dein Skript abzuspeichern! üòâ
